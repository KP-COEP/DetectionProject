{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display as ds\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    main = 'dataset/UCSD_Anomaly_Dataset.v1p2'\n",
    "    train_images = np.load('{}/train.npy'.format(main))\n",
    "    train_images_ = np.load('{}/train_.npy'.format(main))\n",
    "    test_images = np.load('{}/test.npy'.format(main))\n",
    "    test_images = np.load('{}/test_.npy'.format(main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 158, 238, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    latent_feature_count = [10,10,3]\n",
    "    epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self):\n",
    "        with tf.name_scope('Input'):\n",
    "            self.x = tf.placeholder(tf.float32, shape=(None, 158, 238, 3), name='X')\n",
    "            self.x_ = tf.placeholder(tf.float32, shape=(None, 158, 238, 3), name='X_')\n",
    "        \n",
    "        self.encoder, self.decoder = self.build_network(self.x)\n",
    "            \n",
    "    def build_network(self, x):\n",
    "        def encoder(x):\n",
    "            with tf.name_scope('Encoder'):\n",
    "                x = tf.layers.conv2d(x, filters=32, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                print('After 1st Conv', x.get_shape())\n",
    "                x = tf.layers.max_pooling2d(x, pool_size=(5,5), strides=(1,1), )\n",
    "                print('After 1st Pooling', x.get_shape())\n",
    "\n",
    "                x = tf.layers.conv2d(x, filters=16, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                print('After 2nd Conv', x.get_shape())\n",
    "                x = tf.layers.max_pooling2d(x, pool_size=(5,5), strides=(1,1))\n",
    "                print('After 2nd Pooling', x.get_shape())\n",
    "\n",
    "                x = tf.layers.conv2d(x, filters=8, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                print('After 3rd Conv', x.get_shape())\n",
    "                encoded = tf.layers.max_pooling2d(x, pool_size=(5,5), strides=(1,1))\n",
    "                print('After 3rd Pooling (Final Encoded)', x.get_shape())\n",
    "                \n",
    "                latent = tf.layers.dense(tf.contrib.layers.flatten(encoded), \n",
    "                                          units=np.prod(Params.latent_feature_count), \n",
    "                                          activation=tf.nn.relu)\n",
    "                \n",
    "                print('Latent', latent.get_shape())\n",
    "\n",
    "                \n",
    "            return encoded\n",
    "\n",
    "        def decoder(encoded):\n",
    "            with tf.name_scope('Decoder'):\n",
    "                #x = tf.reshape(encoded, [-1] + Params.latent_feature_count)\n",
    "                x = encoded\n",
    "                x = tf.layers.conv2d_transpose(x, filters=8, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                print('After 1st conv transpose', x.get_shape())\n",
    "                x = tf.layers.conv2d_transpose(x, filters=16, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                print('After 2nd conv transpose', x.get_shape())\n",
    "                x = tf.layers.conv2d_transpose(x, filters=32, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                print('After 3rd conv transpose', x.get_shape())\n",
    "                x = tf.layers.conv2d_transpose(x, filters=32, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                print('After 4th conv transpose', x.get_shape())\n",
    "                x = tf.layers.conv2d_transpose(x, filters=3, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                print('After 5th conv transpose', x.get_shape())\n",
    "\n",
    "                decoded = tf.layers.conv2d_transpose(x, filters=3, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                print('After 6th conv transpose (final decoded)', decoded.get_shape())\n",
    "                \n",
    "            return decoded\n",
    "        \n",
    "        return encoder, decoder\n",
    "    \n",
    "    def get_latent(self):\n",
    "        with tf.name_scope('Latent'):\n",
    "            x_ = self.x_\n",
    "            encoded = self.encoder(x_)\n",
    "            \n",
    "        return encoded\n",
    "    \n",
    "    def get_decoded(self):\n",
    "        encoded = self.get_latent()\n",
    "        x_hat = self.decoder(encoded)\n",
    "        return x_hat\n",
    "    \n",
    "    def get_optimizer_loss(self):\n",
    "        \n",
    "        self.x_hat = self.get_decoded()\n",
    "        \n",
    "        with tf.name_scope('Optimization'):\n",
    "            global_step = tf.Variable(0, trainable=False)\n",
    "            loss = tf.losses.mean_squared_error(labels=self.x, predictions=self.x_hat)\n",
    "            tf.summary.scalar(\"loss\",loss)\n",
    "            \n",
    "            starter_learning_rate = 0.001\n",
    "            learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                               100, 0.6, staircase=True)\n",
    "            train = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "            tf.summary.scalar(\"learning_rate\",learning_rate)\n",
    "            \n",
    "        merged = tf.summary.merge_all()\n",
    "        return train, merged, loss\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1st Conv (?, 154, 234, 32)\n",
      "After 1st Pooling (?, 150, 230, 32)\n",
      "After 2nd Conv (?, 146, 226, 16)\n",
      "After 2nd Pooling (?, 142, 222, 16)\n",
      "After 3rd Conv (?, 138, 218, 8)\n",
      "After 3rd Pooling (Final Encoded) (?, 138, 218, 8)\n",
      "WARNING:tensorflow:From /home/kvpcloud/miniconda3/envs/p3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Latent (?, 300)\n",
      "After 1st conv transpose (?, 138, 218, 8)\n",
      "After 2nd conv transpose (?, 142, 222, 16)\n",
      "After 3rd conv transpose (?, 146, 226, 32)\n",
      "After 4th conv transpose (?, 150, 230, 32)\n",
      "After 5th conv transpose (?, 154, 234, 3)\n",
      "After 6th conv transpose (final decoded) (?, 158, 238, 3)\n",
      "After 1st Conv (?, 154, 234, 32)\n",
      "After 1st Pooling (?, 150, 230, 32)\n",
      "After 2nd Conv (?, 146, 226, 16)\n",
      "After 2nd Pooling (?, 142, 222, 16)\n",
      "After 3rd Conv (?, 138, 218, 8)\n",
      "After 3rd Pooling (Final Encoded) (?, 138, 218, 8)\n",
      "Latent (?, 300)\n",
      "epoch: 0 loss: 11037.914\n",
      "epoch: 5 loss: 11536.181\n",
      "epoch: 10 loss: 11536.181\n",
      "epoch: 15 loss: 11536.181\n",
      "epoch: 20 loss: 11536.181\n",
      "epoch: 25 loss: 11536.181\n",
      "epoch: 30 loss: 11536.181\n",
      "epoch: 35 loss: 11536.181\n",
      "epoch: 40 loss: 11536.181\n",
      "epoch: 45 loss: 11536.181\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    network = Network()\n",
    "    optim_loss = network.get_optimizer_loss()\n",
    "    latent = network.get_latent()\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter('logdir/cae_train', sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(Params.epochs):\n",
    "        _, merged, loss = sess.run(optim_loss, feed_dict={network.x:Dataset.train_images,\n",
    "                                                        network.x_: Dataset.train_images})\n",
    "        loss_arr.append(loss)\n",
    "        train_writer.add_summary(merged, epoch)\n",
    "        if epoch % 1 == 0:\n",
    "            print('epoch:', epoch, 'loss:', loss)\n",
    "    \n",
    "    latent_arr = sess.run(latent,feed_dict={network.x:Dataset.train_images,\n",
    "                                            network.x_: Dataset.train_images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f03c6057c50>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('{}/latent_train.npy'.format(Dataset.main),latent_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
