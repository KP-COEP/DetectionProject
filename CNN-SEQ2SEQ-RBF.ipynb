{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display as ds\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.contrib.legacy_seq2seq.python.ops.seq2seq import basic_rnn_seq2seq\n",
    "from tensorflow.contrib.rnn import RNNCell, LSTMCell, MultiRNNCell\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    main = 'dataset/UCSD_Anomaly_Dataset.v1p2'\n",
    "    train_images = np.load('{}/train.npy'.format(main))\n",
    "    train_images_ = np.load('{}/train_.npy'.format(main))\n",
    "    test_images = np.load('{}/test.npy'.format(main))\n",
    "    test_images_ = np.load('{}/test_.npy'.format(main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 158, 238, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.36078431, 0.36078431, 0.36078431],\n",
       "        [0.35686275, 0.35686275, 0.35686275],\n",
       "        [0.31764706, 0.31764706, 0.31764706],\n",
       "        ...,\n",
       "        [0.16470588, 0.16470588, 0.16470588],\n",
       "        [0.22352941, 0.22352941, 0.22352941],\n",
       "        [0.29019608, 0.29019608, 0.29019608]],\n",
       "\n",
       "       [[0.2745098 , 0.2745098 , 0.2745098 ],\n",
       "        [0.2627451 , 0.2627451 , 0.2627451 ],\n",
       "        [0.27843137, 0.27843137, 0.27843137],\n",
       "        ...,\n",
       "        [0.18823529, 0.18823529, 0.18823529],\n",
       "        [0.19215686, 0.19215686, 0.19215686],\n",
       "        [0.33333333, 0.33333333, 0.33333333]],\n",
       "\n",
       "       [[0.30588235, 0.30588235, 0.30588235],\n",
       "        [0.32941176, 0.32941176, 0.32941176],\n",
       "        [0.3372549 , 0.3372549 , 0.3372549 ],\n",
       "        ...,\n",
       "        [0.24705882, 0.24705882, 0.24705882],\n",
       "        [0.16862745, 0.16862745, 0.16862745],\n",
       "        [0.28235294, 0.28235294, 0.28235294]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.41960784, 0.41960784, 0.41960784],\n",
       "        [0.41960784, 0.41960784, 0.41960784],\n",
       "        [0.43137255, 0.43137255, 0.43137255],\n",
       "        ...,\n",
       "        [0.63921569, 0.63921569, 0.63921569],\n",
       "        [0.62352941, 0.62352941, 0.62352941],\n",
       "        [0.70588235, 0.70588235, 0.70588235]],\n",
       "\n",
       "       [[0.44313725, 0.44313725, 0.44313725],\n",
       "        [0.44313725, 0.44313725, 0.44313725],\n",
       "        [0.44705882, 0.44705882, 0.44705882],\n",
       "        ...,\n",
       "        [0.62745098, 0.62745098, 0.62745098],\n",
       "        [0.63137255, 0.63137255, 0.63137255],\n",
       "        [0.69411765, 0.69411765, 0.69411765]],\n",
       "\n",
       "       [[0.45490196, 0.45490196, 0.45490196],\n",
       "        [0.45490196, 0.45490196, 0.45490196],\n",
       "        [0.45882353, 0.45882353, 0.45882353],\n",
       "        ...,\n",
       "        [0.64313725, 0.64313725, 0.64313725],\n",
       "        [0.63137255, 0.63137255, 0.63137255],\n",
       "        [0.72156863, 0.72156863, 0.72156863]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    latent_feature_count = [10,10,3]\n",
    "    cnn_epochs = 30\n",
    "    temp_epochs = 30\n",
    "    rbf_epochs = 30\n",
    "    reduced_feature_rbf_count = 300\n",
    "    frames_for_anomaly = 20\n",
    "    frames_per_batch = frames_for_anomaly * 6\n",
    "    test_batch_size = frames_for_anomaly * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            with tf.name_scope('Input'):\n",
    "                self.x = tf.placeholder(tf.float32, shape=(None, 158, 238, 3), name='X')\n",
    "                self.x_ = tf.placeholder(tf.float32, shape=(None, 158, 238, 3), name='X_')\n",
    "\n",
    "        self.encoder, self.decoder, self.rbf, self.seq2seq = self.build_network(self.x)\n",
    "\n",
    "    def build_network(self, x):\n",
    "        def encoder(x):\n",
    "            with self.graph.as_default():\n",
    "                with tf.variable_scope('CNN/Encoder', reuse=tf.AUTO_REUSE):\n",
    "                    x = tf.layers.conv2d(x, filters=32, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 1st Conv', x.get_shape())\n",
    "                    print(x)\n",
    "                    tf.summary.image('encoder_hidden_1', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.max_pooling2d(x, pool_size=(5,5), strides=(1,1), )\n",
    "                    print('After 1st Pooling', x.get_shape())\n",
    "\n",
    "                    x = tf.layers.conv2d(x, filters=16, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 2nd Conv', x.get_shape())\n",
    "                    tf.summary.image('encoder_hidden_2', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.max_pooling2d(x, pool_size=(5,5), strides=(1,1))\n",
    "                    print('After 2nd Pooling', x.get_shape())\n",
    "\n",
    "                    x = tf.layers.conv2d(x, filters=8, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 3rd Conv', x.get_shape())\n",
    "                    tf.summary.image('encoder_hidden_3', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    encoded = tf.layers.max_pooling2d(x, pool_size=(5,5), strides=(1,1))\n",
    "                    print('After 3rd Pooling (Final Encoded)', x.get_shape())\n",
    "                    tf.summary.image('encoder_hidden_final', encoded[:,:,:,0:3], max_outputs=1)\n",
    "                    \n",
    "                    with tf.name_scope('Latent'):\n",
    "                    \n",
    "                        self.latent = tf.layers.dense(tf.contrib.layers.flatten(encoded), #depricated\n",
    "                                                  units=np.prod(Params.latent_feature_count), \n",
    "                                                  activation=tf.nn.relu)\n",
    "\n",
    "                        print('Latent', self.latent.get_shape())\n",
    "                        tf.summary.histogram('Latent', self.latent)\n",
    "\n",
    "                \n",
    "            return encoded, self.latent\n",
    "\n",
    "        def decoder(encoded):\n",
    "            with self.graph.as_default():\n",
    "                with tf.variable_scope('CNN/Decoder', reuse=tf.AUTO_REUSE):\n",
    "                    #x = tf.reshape(encoded, [-1] + Params.latent_feature_count)\n",
    "                    x = encoded\n",
    "                    x = tf.layers.conv2d_transpose(x, filters=8, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 1st conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_1', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.conv2d_transpose(x, filters=16, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 2nd conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_2', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.conv2d_transpose(x, filters=32, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 3rd conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_3', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.conv2d_transpose(x, filters=32, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 4th conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_4', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.conv2d_transpose(x, filters=3, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 5th conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_5', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    decoded = tf.layers.conv2d_transpose(x, filters=3, kernel_size=(5,5), strides=(1,1), activation=tf.nn.sigmoid)\n",
    "                    print('After 6th conv transpose (final decoded)', decoded.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_decoded', decoded[:,:,:,0:3],max_outputs=1)\n",
    "\n",
    "            return decoded\n",
    "        \n",
    "        def seq2seq(latent):\n",
    "            with tf.variable_scope(\"Seq2Seq\", reuse=tf.AUTO_REUSE):\n",
    "                multi_cell = MultiRNNCell([LSTMCell(300) for i in range(2)] )\n",
    "                \n",
    "                # Grouping 10 images into 1 to form a video clip for which Anomaly detection will be done\n",
    "                print(\"latent \", latent.get_shape())\n",
    "                latent_list = tf.split(latent, Params.frames_for_anomaly, axis=0)\n",
    "                print(\"latent_list for seq2seq \", len(latent_list), latent_list[0].get_shape())\n",
    "                \n",
    "                latent_, states = basic_rnn_seq2seq(latent_list, latent_list, multi_cell)\n",
    "                \n",
    "                print('Context States', states[-1][-1])\n",
    "            return latent_list, latent_, states[-1][-1]\n",
    "\n",
    "        def rbf(lstm_output):\n",
    "            with self.graph.as_default():\n",
    "                def get_cost(U, Z, Q): \n",
    "\n",
    "                    cost = - (-U - tf.log(Z)) \n",
    "                    return tf.reduce_mean(cost)\n",
    "\n",
    "                f = Params.reduced_feature_rbf_count #np.prod(Params.latent_feature_count)\n",
    "\n",
    "\n",
    "                with tf.variable_scope('RBF'):\n",
    "                    X = lstm_output\n",
    "\n",
    "                    mu = tf.layers.dense(X, f, activation=None)\n",
    "                    #mu = tf.Variable(tf.random_uniform([1,f], minval=0.1, dtype=tf.float32))\n",
    "                    mu = tf.print(mu, [mu], \"************ Mu \")\n",
    "\n",
    "                    #Q_ = tf.Variable(tf.truncated_normal([f], mean = 1)) \n",
    "                    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "                    sd = tf.Variable(tf.random_uniform([f], minval=0.1, dtype=tf.float32))\n",
    "\n",
    "                    sigma = tf.square(sd)\n",
    "                    sigma = tf.print(sigma, [sigma], \"************ Sigma (squared) \")\n",
    "                    sigma_inverse = tf.reciprocal(sigma)\n",
    "                    sigma_inverse = tf.print(sigma_inverse, [sigma_inverse], '************* sigma_inverse')\n",
    "\n",
    "                    cov_inverse = tf.diag(sigma_inverse)\n",
    "\n",
    "                    det_sigma = tf.reduce_prod(sigma) #tf.pow(sigma, 0.5))\n",
    "\n",
    "                    z = tf.multiply(2*math.pi, det_sigma)\n",
    "                    z = tf.print(z, [z], ' ******* z')\n",
    "\n",
    "                    with tf.variable_scope('Likelihood'):\n",
    "\n",
    "                        M = X - mu\n",
    "\n",
    "                        energy = tf.matmul(tf.matmul(M,cov_inverse), tf.transpose(M)) \n",
    "                        energy = tf.print(energy, [energy], '*********** energy after matmul', summarize=30)\n",
    "\n",
    "                        energy = tf.matrix_diag_part(energy)\n",
    "                        #print(\"Energy after matmul\", energy.get_shape())\n",
    "\n",
    "\n",
    "                        #energy = tf.reduce_sum(energy, axis = 1, keepdims = True)\n",
    "                        energy = tf.print(energy, [energy], '*********** Energy after summation', summarize=30)\n",
    "                        print('Energy after summation ', energy.get_shape())\n",
    "\n",
    "                        print('X', X.get_shape())\n",
    "                        print('Covariance', cov_inverse.get_shape())\n",
    "\n",
    "                        expnt = tf.exp(-1 * tf.multiply(energy, 0.5))\n",
    "                        print('exponent', expnt.get_shape())\n",
    "                        expnt = tf.print(expnt, [expnt], \"********* Exponent\")\n",
    "\n",
    "                        Y_ = expnt #tf.divide(expnt, z) #expnt #tf.nn.sigmoid(expnt) #tf.divide(expnt, z)\n",
    "\n",
    "\n",
    "                        #Y_ = tf.layers.dense(Y_, 1)\n",
    "                        rbf_out = Y_ #tf.reduce_mean(Y_) # tf.layers.dense(Y_, 1)\n",
    "                        Y_ = tf.print(Y_, [Y_], 'XXXXXXXXXXXXXXXXXXXX Liklihood XXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "                        print('Y_', Y_.get_shape())\n",
    "\n",
    "                    with tf.variable_scope('Loss'):\n",
    "                        #cost = -1 * tf.log(Y_ + 0.0001) # Adding a small delta because log is not a continuous function. \n",
    "                        cost = energy #+ tf.log(z)\n",
    "                        cost = tf.print(cost,[cost], \"******** Cost(always postive)\")\n",
    "                        loss = tf.reduce_mean(cost) #get_cost(U, Z, Q) # 1- Y_[0]\n",
    "                        loss = tf.print(loss, [loss], \"**************** Loss\")\n",
    "                        tf.summary.scalar('loss', loss)\n",
    "\n",
    "            return mu, sd, rbf_out, loss\n",
    "        \n",
    "        return encoder, decoder, rbf, seq2seq\n",
    "    \n",
    "    def get_encoded(self):\n",
    "        with self.graph.as_default():\n",
    "            encoded, latent = self.encoder(self.x_)\n",
    "\n",
    "        return encoded, latent\n",
    "    \n",
    "    def get_decoded(self):\n",
    "        encoded, _ = self.get_encoded()\n",
    "        x_hat = self.decoder(encoded)\n",
    "        return x_hat\n",
    "    \n",
    "    def get_seq2seq(self):\n",
    "        encoded, latent = self.get_encoded()\n",
    "        x_hat = self.decoder(encoded)\n",
    "        latent_list, latent_, states = self.seq2seq(latent)\n",
    "        return latent_list, latent_, states\n",
    "    \n",
    "    def get_rbf(self):\n",
    "        encoded, latent = self.get_encoded()\n",
    "        x_hat = self.decoder(encoded)\n",
    "        _, _, states = self.seq2seq(latent)\n",
    "        print(\"***********States**********\", states.get_shape())\n",
    "        mu, sd, rbf_out, rbf_loss = self.rbf(states)\n",
    "        return x_hat, rbf_loss, rbf_out, mu, sd\n",
    "    \n",
    "    def get_spatial_loss(self, decay_steps):\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            #self.x_hat = self.get_decoded()\n",
    "            self.x_hat = self.get_decoded()\n",
    "            cnn_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"CNN\")\n",
    "            print(cnn_vars)\n",
    "            with tf.name_scope('Optimization'):\n",
    "                global_step = tf.Variable(0, trainable=False)\n",
    "                spatial_loss = tf.losses.mean_squared_error(labels=self.x_, predictions=self.x_hat)\n",
    "                loss = spatial_loss\n",
    "                tf.summary.scalar(\"loss\",loss)\n",
    "\n",
    "                starter_learning_rate = 0.001\n",
    "                learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                                   decay_steps, 0.96, staircase=True)\n",
    "                train = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step, var_list = cnn_vars)\n",
    "                tf.summary.scalar(\"learning_rate\",learning_rate)\n",
    "\n",
    "            merged = tf.summary.merge_all()\n",
    "        return train, merged, loss\n",
    "        \n",
    "    def get_temporal_loss(self, decay_steps):\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            latent_list, latent_, self.states = self.get_seq2seq()\n",
    "            temp_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"Seq2Seq\")\n",
    "            print(temp_vars)\n",
    "            with tf.name_scope('Optimization'):\n",
    "                global_step = tf.Variable(0, trainable=False)\n",
    "                loss = tf.losses.mean_squared_error(latent_list, latent_)\n",
    "                \n",
    "                tf.summary.scalar(\"loss\",loss)\n",
    "\n",
    "                starter_learning_rate = 0.001\n",
    "                learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                                   decay_steps, 0.96, staircase=True)\n",
    "                train = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step, var_list = temp_vars)\n",
    "                tf.summary.scalar(\"learning_rate\",learning_rate)\n",
    "\n",
    "            merged = tf.summary.merge_all()\n",
    "        return train, merged, loss\n",
    "        \n",
    "    def get_rbf_loss(self, decay_steps ):\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            #self.x_hat = self.get_decoded()\n",
    "            self.x_hat, rbf_loss, self.rbf_out, _,_ = self.get_rbf()\n",
    "            rbf_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"RBF\")\n",
    "            print(rbf_vars)\n",
    "            with tf.name_scope('Optimization'):\n",
    "                global_step = tf.Variable(0, trainable=False)\n",
    "                loss = rbf_loss\n",
    "                tf.summary.scalar(\"loss\",loss)\n",
    "\n",
    "                starter_learning_rate = 0.01\n",
    "                learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                                   decay_steps, 0.96, staircase=True)\n",
    "                train = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step, var_list = rbf_vars)\n",
    "                tf.summary.scalar(\"learning_rate\",learning_rate)\n",
    "\n",
    "            merged = tf.summary.merge_all()\n",
    "        return train, merged, loss, self.rbf_out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1st Conv (?, 154, 234, 32)\n",
      "Tensor(\"CNN/Encoder/conv2d/Relu:0\", shape=(?, 154, 234, 32), dtype=float32)\n",
      "After 1st Pooling (?, 150, 230, 32)\n",
      "After 2nd Conv (?, 146, 226, 16)\n",
      "After 2nd Pooling (?, 142, 222, 16)\n",
      "After 3rd Conv (?, 138, 218, 8)\n",
      "After 3rd Pooling (Final Encoded) (?, 138, 218, 8)\n",
      "Latent (?, 300)\n",
      "After 1st conv transpose (?, 138, 218, 8)\n",
      "After 2nd conv transpose (?, 142, 222, 16)\n",
      "After 3rd conv transpose (?, 146, 226, 32)\n",
      "After 4th conv transpose (?, 150, 230, 32)\n",
      "After 5th conv transpose (?, 154, 234, 3)\n",
      "After 6th conv transpose (final decoded) (?, 158, 238, 3)\n",
      "[<tf.Variable 'CNN/Encoder/conv2d/kernel:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'CNN/Encoder/conv2d/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'CNN/Encoder/conv2d_1/kernel:0' shape=(5, 5, 32, 16) dtype=float32_ref>, <tf.Variable 'CNN/Encoder/conv2d_1/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'CNN/Encoder/conv2d_2/kernel:0' shape=(5, 5, 16, 8) dtype=float32_ref>, <tf.Variable 'CNN/Encoder/conv2d_2/bias:0' shape=(8,) dtype=float32_ref>, <tf.Variable 'CNN/Encoder/dense/kernel:0' shape=(229408, 300) dtype=float32_ref>, <tf.Variable 'CNN/Encoder/dense/bias:0' shape=(300,) dtype=float32_ref>, <tf.Variable 'CNN/Decoder/conv2d_transpose/kernel:0' shape=(5, 5, 8, 8) dtype=float32_ref>, <tf.Variable 'CNN/Decoder/conv2d_transpose/bias:0' shape=(8,) dtype=float32_ref>, <tf.Variable 'CNN/Decoder/conv2d_transpose_1/kernel:0' shape=(5, 5, 16, 8) dtype=float32_ref>, <tf.Variable 'CNN/Decoder/conv2d_transpose_1/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'CNN/Decoder/conv2d_transpose_2/kernel:0' shape=(5, 5, 32, 16) dtype=float32_ref>, <tf.Variable 'CNN/Decoder/conv2d_transpose_2/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'CNN/Decoder/conv2d_transpose_3/kernel:0' shape=(5, 5, 32, 32) dtype=float32_ref>, <tf.Variable 'CNN/Decoder/conv2d_transpose_3/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'CNN/Decoder/conv2d_transpose_4/kernel:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'CNN/Decoder/conv2d_transpose_4/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'CNN/Decoder/conv2d_transpose_5/kernel:0' shape=(5, 5, 3, 3) dtype=float32_ref>, <tf.Variable 'CNN/Decoder/conv2d_transpose_5/bias:0' shape=(3,) dtype=float32_ref>]\n",
      "After 1st Conv (?, 154, 234, 32)\n",
      "Tensor(\"CNN/Encoder_1/conv2d/Relu:0\", shape=(?, 154, 234, 32), dtype=float32)\n",
      "After 1st Pooling (?, 150, 230, 32)\n",
      "After 2nd Conv (?, 146, 226, 16)\n",
      "After 2nd Pooling (?, 142, 222, 16)\n",
      "After 3rd Conv (?, 138, 218, 8)\n",
      "After 3rd Pooling (Final Encoded) (?, 138, 218, 8)\n",
      "Latent (?, 300)\n",
      "After 1st conv transpose (?, 138, 218, 8)\n",
      "After 2nd conv transpose (?, 142, 222, 16)\n",
      "After 3rd conv transpose (?, 146, 226, 32)\n",
      "After 4th conv transpose (?, 150, 230, 32)\n",
      "After 5th conv transpose (?, 154, 234, 3)\n",
      "After 6th conv transpose (final decoded) (?, 158, 238, 3)\n",
      "latent  (?, 300)\n",
      "latent_list for seq2seq  20 (?, 300)\n",
      "Context States Tensor(\"Seq2Seq/basic_rnn_seq2seq/rnn_decoder/rnn_decoder/multi_rnn_cell/cell_1/lstm_cell/mul_59:0\", shape=(?, 300), dtype=float32)\n",
      "[<tf.Variable 'Seq2Seq/basic_rnn_seq2seq/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0' shape=(600, 1200) dtype=float32_ref>, <tf.Variable 'Seq2Seq/basic_rnn_seq2seq/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'Seq2Seq/basic_rnn_seq2seq/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0' shape=(600, 1200) dtype=float32_ref>, <tf.Variable 'Seq2Seq/basic_rnn_seq2seq/rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'Seq2Seq/basic_rnn_seq2seq/rnn_decoder/multi_rnn_cell/cell_0/lstm_cell/kernel:0' shape=(600, 1200) dtype=float32_ref>, <tf.Variable 'Seq2Seq/basic_rnn_seq2seq/rnn_decoder/multi_rnn_cell/cell_0/lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'Seq2Seq/basic_rnn_seq2seq/rnn_decoder/multi_rnn_cell/cell_1/lstm_cell/kernel:0' shape=(600, 1200) dtype=float32_ref>, <tf.Variable 'Seq2Seq/basic_rnn_seq2seq/rnn_decoder/multi_rnn_cell/cell_1/lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>]\n",
      "After 1st Conv (?, 154, 234, 32)\n",
      "Tensor(\"CNN/Encoder_2/conv2d/Relu:0\", shape=(?, 154, 234, 32), dtype=float32)\n",
      "After 1st Pooling (?, 150, 230, 32)\n",
      "After 2nd Conv (?, 146, 226, 16)\n",
      "After 2nd Pooling (?, 142, 222, 16)\n",
      "After 3rd Conv (?, 138, 218, 8)\n",
      "After 3rd Pooling (Final Encoded) (?, 138, 218, 8)\n",
      "Latent (?, 300)\n",
      "After 1st conv transpose (?, 138, 218, 8)\n",
      "After 2nd conv transpose (?, 142, 222, 16)\n",
      "After 3rd conv transpose (?, 146, 226, 32)\n",
      "After 4th conv transpose (?, 150, 230, 32)\n",
      "After 5th conv transpose (?, 154, 234, 3)\n",
      "After 6th conv transpose (final decoded) (?, 158, 238, 3)\n",
      "latent  (?, 300)\n",
      "latent_list for seq2seq  20 (?, 300)\n",
      "Context States Tensor(\"Seq2Seq_1/basic_rnn_seq2seq/rnn_decoder/rnn_decoder/multi_rnn_cell/cell_1/lstm_cell/mul_59:0\", shape=(?, 300), dtype=float32)\n",
      "***********States********** (?, 300)\n",
      "Energy after summation  (?,)\n",
      "X (?, 300)\n",
      "Covariance (300, 300)\n",
      "exponent (?,)\n",
      "Y_ (?,)\n",
      "[<tf.Variable 'RBF/dense/kernel:0' shape=(300, 300) dtype=float32_ref>, <tf.Variable 'RBF/dense/bias:0' shape=(300,) dtype=float32_ref>, <tf.Variable 'RBF/Variable_1:0' shape=(300,) dtype=float32_ref>]\n",
      "Training CNN only\n",
      "epoch: 0 loss: 0.044816643\n",
      "Freezing CNN and Training LSTM Seq2Seq only\n",
      "epoch: 0 loss: 0.00079946104\n",
      "Freezing CNN and LSTM and Training RBF only\n",
      "epoch: 0 loss: 11.309364 liklihood [0.00350109]\n"
     ]
    }
   ],
   "source": [
    "loss_spatial_arr=[]\n",
    "loss_temp_arr=[]\n",
    "loss_rbf_arr=[]\n",
    "\n",
    "network = Network()\n",
    "m_b_s = Params.frames_for_anomaly\n",
    "\n",
    "with tf.Session(graph=network.graph) as sess:\n",
    "\n",
    "    # Training only CNN\n",
    "    optim_spatial_loss = network.get_spatial_loss(int(Params.cnn_epochs / 3))\n",
    "    optim_temp_loss = network.get_temporal_loss(int(Params.temp_epochs / 3))\n",
    "    optim_rbf_loss = network.get_rbf_loss(int(Params.rbf_epochs / 3))\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter('logdir/CNN-SEQ2SEQ-RBF_cnn_train', sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Training CNN only\")\n",
    "    for epoch in range(Params.cnn_epochs):\n",
    "        m_b_s_old = 0\n",
    "        for m_b_s_new in range(m_b_s, Dataset.train_images_.shape[0], m_b_s  ):\n",
    "            _, merged, loss = sess.run(optim_spatial_loss, feed_dict={network.x:Dataset.train_images_[m_b_s_old:m_b_s_new,:],\n",
    "                                                            network.x_: Dataset.train_images[m_b_s_old:m_b_s_new,:]})\n",
    "            m_b_s_old = m_b_s_new\n",
    "        if epoch % 30 == 0 or epoch == Params.cnn_epochs:\n",
    "            print('epoch:', epoch, 'loss:', loss)\n",
    "            train_writer.add_summary(merged, epoch)\n",
    "            loss_spatial_arr.append(loss)\n",
    "        \n",
    "    \n",
    "    train_writer = tf.summary.FileWriter('logdir/CNN-SEQ2SEQ-RBF_temporal_train', sess.graph)\n",
    "    print(\"Freezing CNN and Training LSTM Seq2Seq only\")\n",
    "    for epoch in range(Params.temp_epochs):\n",
    "        m_b_s_old = 0\n",
    "        for m_b_s_new in range(m_b_s, Dataset.train_images_.shape[0], m_b_s  ):\n",
    "            _, merged, loss = sess.run(optim_temp_loss, feed_dict={network.x:Dataset.train_images_[m_b_s_old:m_b_s_new,:],\n",
    "                                                            network.x_: Dataset.train_images[m_b_s_old:m_b_s_new,:]})\n",
    "            m_b_s_old = m_b_s_new\n",
    "        if epoch % 30 == 0 or epoch == Params.temp_epochs:\n",
    "            print('epoch:', epoch, 'loss:', loss)\n",
    "            train_writer.add_summary(merged, epoch)\n",
    "            loss_temp_arr.append(loss)\n",
    "        \n",
    "    train_writer = tf.summary.FileWriter('logdir/CNN-SEQ2SEQ-RBF_rbf_train', sess.graph)\n",
    "    print(\"Freezing CNN and LSTM and Training RBF only\")\n",
    "    for epoch in range(Params.rbf_epochs):\n",
    "        m_b_s_old = 0\n",
    "        for m_b_s_new in range(m_b_s, Dataset.train_images_.shape[0], m_b_s  ):\n",
    "            _, merged, loss, liklihood = sess.run(optim_rbf_loss, feed_dict={network.x:Dataset.train_images_[m_b_s_old:m_b_s_new,:],\n",
    "                                                            network.x_: Dataset.train_images[m_b_s_old:m_b_s_new,:]})\n",
    "            m_b_s_old = m_b_s_new\n",
    "        if epoch % 30 == 0 or epoch == Params.rbf_epochs:\n",
    "            print('epoch:', epoch, 'loss:', loss, 'liklihood', liklihood)\n",
    "            train_writer.add_summary(merged, epoch)\n",
    "            loss_rbf_arr.append(loss)\n",
    "        \n",
    "    Dataset.latent, Dataset.rbf_out = sess.run([network.latent, network.rbf_out],feed_dict={network.x:Dataset.test_images_[:Params.test_batch_size,:],\n",
    "                                            network.x_: Dataset.train_images[:Params.test_batch_size,:]})\n",
    "    Dataset.reproduced_images = sess.run(network.x_hat,feed_dict={network.x:Dataset.test_images_[:Params.test_batch_size,:],\n",
    "                                            network.x_: Dataset.test_images[:Params.test_batch_size,:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f37282d7cc0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_spatial_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_temp_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5bd6ed46ef68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_temp_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_temp_arr' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(loss_temp_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_rbf_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('{}/latent_train'.format(Dataset.main),Dataset.latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5, figsize=(25,8))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, imgs in enumerate(Dataset.reproduced_images[10:20]):\n",
    "    axs[i].imshow(imgs[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs[0].imshow(Dataset.reproduced_images[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.reproduced_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.reproduced_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5, figsize=(25,8))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, imgs in enumerate(Dataset.test_images_[10:20]):\n",
    "    axs[i].imshow(imgs[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
