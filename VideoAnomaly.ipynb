{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display as ds\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    main = 'dataset/UCSD_Anomaly_Dataset.v1p2'\n",
    "    train_images = np.load('{}/train.npy'.format(main))\n",
    "    train_images_ = np.load('{}/train_.npy'.format(main))\n",
    "    test_images = np.load('{}/test.npy'.format(main))\n",
    "    test_images_ = np.load('{}/test_.npy'.format(main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 158, 238, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.36078431, 0.36078431, 0.36078431],\n",
       "        [0.35686275, 0.35686275, 0.35686275],\n",
       "        [0.31764706, 0.31764706, 0.31764706],\n",
       "        ...,\n",
       "        [0.16470588, 0.16470588, 0.16470588],\n",
       "        [0.22352941, 0.22352941, 0.22352941],\n",
       "        [0.29019608, 0.29019608, 0.29019608]],\n",
       "\n",
       "       [[0.2745098 , 0.2745098 , 0.2745098 ],\n",
       "        [0.2627451 , 0.2627451 , 0.2627451 ],\n",
       "        [0.27843137, 0.27843137, 0.27843137],\n",
       "        ...,\n",
       "        [0.18823529, 0.18823529, 0.18823529],\n",
       "        [0.19215686, 0.19215686, 0.19215686],\n",
       "        [0.33333333, 0.33333333, 0.33333333]],\n",
       "\n",
       "       [[0.30588235, 0.30588235, 0.30588235],\n",
       "        [0.32941176, 0.32941176, 0.32941176],\n",
       "        [0.3372549 , 0.3372549 , 0.3372549 ],\n",
       "        ...,\n",
       "        [0.24705882, 0.24705882, 0.24705882],\n",
       "        [0.16862745, 0.16862745, 0.16862745],\n",
       "        [0.28235294, 0.28235294, 0.28235294]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.41960784, 0.41960784, 0.41960784],\n",
       "        [0.41960784, 0.41960784, 0.41960784],\n",
       "        [0.43137255, 0.43137255, 0.43137255],\n",
       "        ...,\n",
       "        [0.63921569, 0.63921569, 0.63921569],\n",
       "        [0.62352941, 0.62352941, 0.62352941],\n",
       "        [0.70588235, 0.70588235, 0.70588235]],\n",
       "\n",
       "       [[0.44313725, 0.44313725, 0.44313725],\n",
       "        [0.44313725, 0.44313725, 0.44313725],\n",
       "        [0.44705882, 0.44705882, 0.44705882],\n",
       "        ...,\n",
       "        [0.62745098, 0.62745098, 0.62745098],\n",
       "        [0.63137255, 0.63137255, 0.63137255],\n",
       "        [0.69411765, 0.69411765, 0.69411765]],\n",
       "\n",
       "       [[0.45490196, 0.45490196, 0.45490196],\n",
       "        [0.45490196, 0.45490196, 0.45490196],\n",
       "        [0.45882353, 0.45882353, 0.45882353],\n",
       "        ...,\n",
       "        [0.64313725, 0.64313725, 0.64313725],\n",
       "        [0.63137255, 0.63137255, 0.63137255],\n",
       "        [0.72156863, 0.72156863, 0.72156863]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    latent_feature_count = [10,10,3]\n",
    "    epochs = 30\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            with tf.name_scope('Input'):\n",
    "                self.x = tf.placeholder(tf.float32, shape=(None, 158, 238, 3), name='X')\n",
    "                self.x_ = tf.placeholder(tf.float32, shape=(None, 158, 238, 3), name='X_')\n",
    "                \n",
    "            self.cn = self.CreateNetwork(self.graph, self.x_)\n",
    "            \n",
    "    class CreateNetwork:\n",
    "        def __init__(self, graph, x_):\n",
    "            self.graph = graph\n",
    "            self.x_ = x_\n",
    "            \n",
    "        def encoder(self, x):\n",
    "            with self.graph.as_default():\n",
    "                with tf.name_scope('Encoder'):\n",
    "                    x = tf.layers.conv2d(x, filters=32, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 1st Conv', x.get_shape())\n",
    "                    tf.summary.image('encoder_hidden_1', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.max_pooling2d(x, pool_size=(5,5), strides=(1,1), )\n",
    "                    print('After 1st Pooling', x.get_shape())\n",
    "\n",
    "                    x = tf.layers.conv2d(x, filters=16, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 2nd Conv', x.get_shape())\n",
    "                    tf.summary.image('encoder_hidden_2', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.max_pooling2d(x, pool_size=(5,5), strides=(1,1))\n",
    "                    print('After 2nd Pooling', x.get_shape())\n",
    "\n",
    "                    x = tf.layers.conv2d(x, filters=8, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 3rd Conv', x.get_shape())\n",
    "                    tf.summary.image('encoder_hidden_3', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    encoded = tf.layers.max_pooling2d(x, pool_size=(5,5), strides=(1,1))\n",
    "                    print('After 3rd Pooling (Final Encoded)', x.get_shape())\n",
    "                    tf.summary.image('encoder_hidden_final', encoded[:,:,:,0:3], max_outputs=1)\n",
    "                    \n",
    "                    with tf.name_scope('Latent'):\n",
    "                    \n",
    "                        latent = tf.layers.dense(tf.contrib.layers.flatten(encoded), #depricated\n",
    "                                                  units=np.prod(Params.latent_feature_count), \n",
    "                                                  activation=tf.nn.relu)\n",
    "\n",
    "                        print('Latent', latent.get_shape())\n",
    "                        tf.summary.histogram('Latent', latent)\n",
    "\n",
    "                \n",
    "            return encoded, latent\n",
    "\n",
    "        def decoder(self, encoded):\n",
    "            with self.graph.as_default():\n",
    "                with tf.name_scope('Decoder'):\n",
    "                    #x = tf.reshape(encoded, [-1] + Params.latent_feature_count)\n",
    "                    x = encoded\n",
    "                    x = tf.layers.conv2d_transpose(x, filters=8, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 1st conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_1', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.conv2d_transpose(x, filters=16, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 2nd conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_2', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.conv2d_transpose(x, filters=32, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 3rd conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_3', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.conv2d_transpose(x, filters=32, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 4th conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_4', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.conv2d_transpose(x, filters=3, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 5th conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_5', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    decoded = tf.layers.conv2d_transpose(x, filters=3, kernel_size=(5,5), strides=(1,1), activation=tf.nn.sigmoid)\n",
    "                    print('After 6th conv transpose (final decoded)', decoded.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_decoded', decoded[:,:,:,0:3],max_outputs=1)\n",
    "\n",
    "                with tf.name_scope('Loss'):\n",
    "                    loss = tf.losses.mean_squared_error(labels=self.x_, predictions=decoded)\n",
    "                    tf.summary.scalar(\"loss\",loss)\n",
    "                    \n",
    "            return decoded, loss\n",
    "        \n",
    "        def lstm(self, latent):\n",
    "            with self.graph.as_default():\n",
    "                \n",
    "                with tf.name_scope('LSTM') as lstm_scope:\n",
    "                    x = tf.layers.dense(latent, units=np.prod(Params.latent_feature_count), activation=tf.nn.relu)\n",
    "\n",
    "                    lstm = tf.contrib.rnn.BasicLSTMCell(512)\n",
    "                    x_list = tf.split(x, 10, axis=0)\n",
    "\n",
    "                    y_list, self.state = tf.nn.static_rnn(lstm, x_list, dtype = tf.float32)\n",
    "                    \n",
    "                    lstm_out = tf.stack(y_list[-1]) # we only need the last output\n",
    "                    lstm_out = tf.layers.dense(lstm_out, np.prod(Params.latent_feature_count))\n",
    "        \n",
    "            return lstm_out\n",
    "        \n",
    "        def rbf(self, lstm_output):\n",
    "            with self.graph.as_default():\n",
    "                def get_cost(U, Z, Q): \n",
    "                    \n",
    "                    cost = - (-U - tf.log(Z)) \n",
    "                    return tf.reduce_mean(cost)\n",
    "\n",
    "                f = np.prod(Params.latent_feature_count)\n",
    "\n",
    "                \n",
    "                with tf.name_scope('RBF'):\n",
    "                    X = lstm_output\n",
    "\n",
    "                    P = tf.Variable(tf.truncated_normal([f]))\n",
    "                    Q_ = tf.Variable(tf.truncated_normal([f])) \n",
    "                    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "\n",
    "                    Q = tf.diag(tf.square(Q_)) + tf.eye(f) \n",
    "\n",
    "                    X = tf.layers.dense(X, f)\n",
    "                    X = tf.layers.dense(X, f)  \n",
    "\n",
    "                    with tf.name_scope('Likelihood'):\n",
    "                        \n",
    "                        M = P - tf.matmul(X, Q)\n",
    "                        \n",
    "                        R = tf.matmul(M, Q)\n",
    "                        \n",
    "                        V = tf.matmul(R, tf.transpose(M))\n",
    "                        \n",
    "                        U = tf.reduce_sum(V, axis = 1, keepdims = True)\n",
    "                        \n",
    "                        Q_det = tf.matrix_determinant(Q)\n",
    "                        \n",
    "                        Z = tf.pow(tf.multiply(tf.pow(2*math.pi,f), Q_det), 1/2)\n",
    "                        \n",
    "                        Y_ = tf.divide(tf.exp(-U/2), Z)\n",
    "                        \n",
    "                        Y_ = tf.layers.dense(Y_, 1)\n",
    "                        rbf_out = tf.layers.dense(Y_, 1)\n",
    "\n",
    "\n",
    "                    with tf.name_scope('Loss'):\n",
    "                        loss = get_cost(U, Z, Q) # 1- Y_[0]\n",
    "                        tf.summary.scalar('loss', loss)\n",
    "\n",
    "            return rbf_out, loss\n",
    "\n",
    "        \n",
    "    def initialize_spatial(self):\n",
    "        # encoder, decoder, lstm, rbf = \n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            with tf.name_scope('Spatial_Autoencoder'):\n",
    "                encoded, latent = self.cn.encoder(self.x)\n",
    "                print(\"Encoder: \", encoded.get_shape())\n",
    "                tf.summary.histogram(\"Encoded\", encoded)\n",
    "                \n",
    "                self.decoded, spatial_loss = self.cn.decoder(encoded)\n",
    "                print(\"Decoder: \", self.decoded.get_shape())\n",
    "                tf.summary.histogram(\"Decoded\", self.decoded)\n",
    "                tf.summary.scalar(\"Spatial_Loss\", spatial_loss)\n",
    "                \n",
    "        return latent, spatial_loss\n",
    "                \n",
    "    def intialize_temportal(self, latent):\n",
    "        with self.graph.as_default():\n",
    "            with tf.name_scope('Temporal_Autoencoder'):\n",
    "                lstm_out = self.cn.lstm(latent)\n",
    "                print(\"LSTM: \", lstm_out.get_shape())\n",
    "                tf.summary.histogram(\"LSTM\", lstm_out)\n",
    "\n",
    "                likelihood, likelihood_loss = self.cn.rbf(lstm_out)\n",
    "                print(\"Likelihood: \", likelihood.get_shape())\n",
    "                tf.summary.scalar(\"Temporal_Loss\", likelihood_loss)\n",
    "                \n",
    "        return likelihood, likelihood_loss\n",
    "\n",
    "    \n",
    "    def get_optimizer_loss(self):\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            \n",
    "            latent, spatial_loss = self.initialize_spatial()\n",
    "            #self.likelihood, likelihood_loss = self.initialize_temporal(latent)\n",
    "            \n",
    "            loss = spatial_loss #+ likelihood_loss\n",
    "            tf.summary.scalar(\"Total_Loss\", loss)\n",
    "            \n",
    "            with tf.name_scope('Optimization'):\n",
    "                \n",
    "                global_step = tf.Variable(0, trainable=False)\n",
    "                starter_learning_rate = 0.001\n",
    "                learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                                   int(Params.epochs / 3), 0.5, staircase=True)\n",
    "                train = tf.train.GradientDescentOptimizer(learning_rate).minimize(spatial_loss, global_step=global_step)\n",
    "                tf.summary.scalar(\"learning_rate\",learning_rate)\n",
    "\n",
    "            merged = tf.summary.merge_all()\n",
    "        return train, merged, loss\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1st Conv (?, 154, 234, 32)\n",
      "After 1st Pooling (?, 150, 230, 32)\n",
      "After 2nd Conv (?, 146, 226, 16)\n",
      "After 2nd Pooling (?, 142, 222, 16)\n",
      "After 3rd Conv (?, 138, 218, 8)\n",
      "After 3rd Pooling (Final Encoded) (?, 138, 218, 8)\n",
      "Latent (?, 300)\n",
      "Encoder:  (?, 134, 214, 8)\n",
      "After 1st conv transpose (?, 138, 218, 8)\n",
      "After 2nd conv transpose (?, 142, 222, 16)\n",
      "After 3rd conv transpose (?, 146, 226, 32)\n",
      "After 4th conv transpose (?, 150, 230, 32)\n",
      "After 5th conv transpose (?, 154, 234, 3)\n",
      "After 6th conv transpose (final decoded) (?, 158, 238, 3)\n",
      "Decoder:  (?, 158, 238, 3)\n",
      "epoch: 0 loss: 0.05547515\n"
     ]
    }
   ],
   "source": [
    "loss_arr=[]\n",
    "network = Network()\n",
    "with tf.Session(graph=network.graph) as sess:\n",
    "\n",
    "    \n",
    "    optim_loss = network.get_optimizer_loss()\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter('logdir/cae_train', sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(Params.epochs):\n",
    "        _, merged, loss = sess.run(optim_loss, feed_dict={network.x:Dataset.train_images_,\n",
    "                                                        network.x_: Dataset.train_images})\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print('epoch:', epoch, 'loss:', loss)\n",
    "            train_writer.add_summary(merged, epoch)\n",
    "            loss_arr.append(loss)\n",
    "    \n",
    "    #Dataset.latent = sess.run(network.latent,feed_dict={network.x:Dataset.train_images_,\n",
    "    #                                        network.x_: Dataset.train_images})\n",
    "    \n",
    "    Dataset.likelihood, Dataset.reproduced_images = sess.run((network.likelihood, network.decoded),feed_dict={network.x:Dataset.test_images_,\n",
    "                                            network.x_: Dataset.test_images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5, figsize=(25,8))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, imgs in enumerate(Dataset.reproduced_images[15:25]):\n",
    "    axs[i].imshow(imgs[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs[0].imshow(Dataset.reproduced_images[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.reproduced_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.reproduced_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5, figsize=(25,8))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, imgs in enumerate(Dataset.test_images_[15:25]):\n",
    "    axs[i].imshow(imgs[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
