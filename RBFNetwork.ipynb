{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Gaussian Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Samples\n",
    "\n",
    "We are going to demostrate the RBF network for 3 dimensional Guassian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\",15)\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hp:\n",
    "    n = 1000\n",
    "    f = 2\n",
    "\n",
    "train_mean = np.full(shape=(hp.f), fill_value = 0.5)\n",
    "train_var = [[1,0.6],[0.2,3]]\n",
    "train_var = np.matmul(train_var, np.transpose(train_var)) # To make sure that the covariance matrix in positive semi-definate\n",
    "\n",
    "test_mean_1 = np.full(shape=(hp.f), fill_value = 1.2)\n",
    "test_var_1 = [[1,1.6],[0.6,2]]\n",
    "test_var_1 = np.matmul(test_var_1, np.transpose(test_var_1))\n",
    "\n",
    "test_mean_2 = np.full(shape=(hp.f), fill_value = 10)\n",
    "test_var_2 = [[1,0.6],[2.2,3]]\n",
    "test_var_2 = np.matmul(test_var_2, np.transpose(test_var_2))\n",
    "\n",
    "test_mean_3 = np.full(shape=(hp.f), fill_value = 20)\n",
    "test_var_3 = [[1,0.6],[0.2,3]]\n",
    "test_var_3 = np.matmul(test_var_3, np.transpose(test_var_3))\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    train_positive = pd.DataFrame(\n",
    "        np.random.multivariate_normal(mean=train_mean, cov=train_var, size = hp.n))\n",
    "    \n",
    "    test_negative_1 = pd.DataFrame(\n",
    "        np.random.multivariate_normal(mean=test_mean_1, cov=test_var_1, size = hp.n))\n",
    "    \n",
    "    test_negative_2 = pd.DataFrame(\n",
    "        np.random.multivariate_normal(mean=test_mean_2, cov=test_var_2, size = hp.n))\n",
    "    \n",
    "    test_negative_3 = pd.DataFrame(\n",
    "        np.random.multivariate_normal(mean=test_mean_3, cov=test_var_3, size = hp.n))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.train_positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data (Normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.train_positive.plot.scatter(x=0, y=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Data 1 (Anamoly)\n",
    "\n",
    "Similar Mean Different Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.test_negative_1.plot.scatter(x=0, y=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Data 2 (Anamoly)\n",
    "\n",
    "Different Mean Different Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.test_negative_2.plot.scatter(x=0, y=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Data 3 (Anamoly)\n",
    "\n",
    "Different Mean similar Variation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.test_negative_3.plot.scatter(x=0, y=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Dataset.train_positive[0], Dataset.train_positive[1], 'y+', label='train')\n",
    "\n",
    "plt.plot(Dataset.test_negative_1[0], Dataset.test_negative_1[1], 'b.', label='Test 1')\n",
    "plt.plot(Dataset.test_negative_2[0], Dataset.test_negative_2[1], 'r.', label='Test 2')\n",
    "plt.plot(Dataset.test_negative_3[0], Dataset.test_negative_3[1], 'g.', label='Test 3')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    \n",
    "    params = {}\n",
    "    \n",
    "    def __init__(self):\n",
    "        with tf.name_scope('Input'):\n",
    "            self.X = tf.placeholder(tf.float32, [hp.n, hp.f],name='Variable_X') #hp.n, hp.f\n",
    "        \n",
    "    def get_cost(self, U, Z, Q): #U, Q, Q_, Z\n",
    "        \n",
    "        #inverse_regularizer = tf.pow((tf.matmul(Q,tf.transpose(Q)) - tf.eye(hp.f)), 2)\n",
    "        cost = - (-U - tf.log(Z)) #+ tf.reduce_sum(inverse_regularizer,axis =1) # get -ve log likelihood\n",
    "        \n",
    "        #self.params.update({'U':tf.reduce_mean(U)}) #, 'ir': tf.reduce_sum(inverse_regularizer)\n",
    "        return tf.reduce_mean(cost)\n",
    "    \n",
    "    def get_optimizer(self):\n",
    "        \n",
    "        with tf.name_scope('Weights'):\n",
    "            n = hp.n\n",
    "            f = hp.f\n",
    "\n",
    "            X = self.X\n",
    "\n",
    "            P = tf.Variable(tf.truncated_normal([f]))\n",
    "            Q_ = tf.Variable(tf.truncated_normal([f])) \n",
    "            #Q_ = tf.Variable(tf.truncated_normal([f,f])) \n",
    "            global_step = tf.Variable(0, trainable=False)\n",
    "            \n",
    "        with tf.name_scope('RBF'):\n",
    "            Q = tf.diag(tf.square(Q_)) + tf.eye(f) \n",
    "            #Q = tf.matmul(Q_, tf.transpose(Q_)) # Making is positive semi-definite\n",
    "\n",
    "            X = tf.layers.dense(X, f)\n",
    "            X = tf.layers.dense(X, f)\n",
    "\n",
    "            M = P - tf.matmul(X, Q)\n",
    "            print('M', M.get_shape())\n",
    "\n",
    "            R = tf.matmul(M, Q)\n",
    "            print('R', R.get_shape())\n",
    "\n",
    "            V = tf.matmul(R, tf.transpose(M))\n",
    "            print('V', V.get_shape())\n",
    "\n",
    "            U = tf.reduce_sum(V, axis = 1, keepdims = True)\n",
    "            print('U', U.get_shape())\n",
    "\n",
    "            Q_det = tf.matrix_determinant(Q)\n",
    "            print('Q_det', Q_det.get_shape())\n",
    "\n",
    "            Z = tf.pow(tf.multiply(tf.pow(2*math.pi,f), Q_det), 1/2)\n",
    "            print('Z', Z.get_shape())\n",
    "        \n",
    "        with tf.name_scope('Likelihood'):\n",
    "            Y_ = tf.divide(tf.exp(-U/2), Z)\n",
    "            print(\"Y_\", Y_.get_shape())\n",
    "            Y_ = tf.layers.dense(Y_, 1)\n",
    "            Y_ = tf.layers.dense(Y_, 1)\n",
    "            \n",
    "            \n",
    "        with tf.name_scope('LossAndOptim'):\n",
    "            loss = self.get_cost(U, Z, Q) # 1- Y_[0]\n",
    "            tf.summary.scalar('loss', loss)\n",
    "\n",
    "            starter_learning_rate = 0.01\n",
    "            learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                               1000, 0.6, staircase=True)\n",
    "            train = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "            tf.summary.scalar(\"learning_rate\",learning_rate)\n",
    "            \n",
    "        merged = tf.summary.merge_all()\n",
    "        \n",
    "        self.params.update({'U': U, 'P':P, 'Q':Q, 'Z':Z, 'Q_det':Q_det, 'Y_':Y_}) #  \n",
    "\n",
    "        return merged, train, loss, Y_, self.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20000\n",
    "loss_arr = []\n",
    "Dataset.Y_ = []\n",
    "\n",
    "net = network()\n",
    "output_tensors = net.get_optimizer()\n",
    "\n",
    "# tf_debug.TensorBoardDebugWrapperSession(tf.Session(), 'localhost:6064')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    train_writer = tf.summary.FileWriter('logdir/rbf_train', sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        X = np.reshape(Dataset.train_positive.values, (hp.n, -1))\n",
    "        \n",
    "        #for i in range(X.shape[0]):\n",
    "        #x = X#[i,:].reshape((1,-1))\n",
    "        \n",
    "        merged, train, loss, Y_, params = sess.run(output_tensors, feed_dict={net.X:X}) \n",
    "        \n",
    "        train_writer.add_summary(merged, epoch)\n",
    "        loss_arr.append(loss)\n",
    "\n",
    "        if(epoch % 500 == 0):\n",
    "            print(\"epoch\", epoch, \"loss\", loss)#, 'U', params['U'], 'Z', params['Z']) #, 'IR', params['ir'], 'Z', params['Z'], 'U', params['U']\n",
    "\n",
    "        Dataset.Y_.append(Y_)\n",
    "        \n",
    "    print('P (Mean)', params['P'])\n",
    "    print('Q (Covariance)', params['Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(0, 5)\n",
    "plt.plot(loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=params['Y_'].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
