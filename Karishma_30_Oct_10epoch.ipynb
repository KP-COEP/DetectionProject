{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display as ds\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    main = 'dataset/UCSD_Anomaly_Dataset.v1p2'\n",
    "    train_images = np.load('{}/train.npy'.format(main))\n",
    "    train_images_ = np.load('{}/train_.npy'.format(main))\n",
    "    test_images = np.load('{}/test.npy'.format(main))\n",
    "    test_images_ = np.load('{}/test_.npy'.format(main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 158, 238, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.36078431, 0.36078431, 0.36078431],\n",
       "        [0.35686275, 0.35686275, 0.35686275],\n",
       "        [0.31764706, 0.31764706, 0.31764706],\n",
       "        ...,\n",
       "        [0.16470588, 0.16470588, 0.16470588],\n",
       "        [0.22352941, 0.22352941, 0.22352941],\n",
       "        [0.29019608, 0.29019608, 0.29019608]],\n",
       "\n",
       "       [[0.2745098 , 0.2745098 , 0.2745098 ],\n",
       "        [0.2627451 , 0.2627451 , 0.2627451 ],\n",
       "        [0.27843137, 0.27843137, 0.27843137],\n",
       "        ...,\n",
       "        [0.18823529, 0.18823529, 0.18823529],\n",
       "        [0.19215686, 0.19215686, 0.19215686],\n",
       "        [0.33333333, 0.33333333, 0.33333333]],\n",
       "\n",
       "       [[0.30588235, 0.30588235, 0.30588235],\n",
       "        [0.32941176, 0.32941176, 0.32941176],\n",
       "        [0.3372549 , 0.3372549 , 0.3372549 ],\n",
       "        ...,\n",
       "        [0.24705882, 0.24705882, 0.24705882],\n",
       "        [0.16862745, 0.16862745, 0.16862745],\n",
       "        [0.28235294, 0.28235294, 0.28235294]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.41960784, 0.41960784, 0.41960784],\n",
       "        [0.41960784, 0.41960784, 0.41960784],\n",
       "        [0.43137255, 0.43137255, 0.43137255],\n",
       "        ...,\n",
       "        [0.63921569, 0.63921569, 0.63921569],\n",
       "        [0.62352941, 0.62352941, 0.62352941],\n",
       "        [0.70588235, 0.70588235, 0.70588235]],\n",
       "\n",
       "       [[0.44313725, 0.44313725, 0.44313725],\n",
       "        [0.44313725, 0.44313725, 0.44313725],\n",
       "        [0.44705882, 0.44705882, 0.44705882],\n",
       "        ...,\n",
       "        [0.62745098, 0.62745098, 0.62745098],\n",
       "        [0.63137255, 0.63137255, 0.63137255],\n",
       "        [0.69411765, 0.69411765, 0.69411765]],\n",
       "\n",
       "       [[0.45490196, 0.45490196, 0.45490196],\n",
       "        [0.45490196, 0.45490196, 0.45490196],\n",
       "        [0.45882353, 0.45882353, 0.45882353],\n",
       "        ...,\n",
       "        [0.64313725, 0.64313725, 0.64313725],\n",
       "        [0.63137255, 0.63137255, 0.63137255],\n",
       "        [0.72156863, 0.72156863, 0.72156863]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    latent_feature_count = [10,10,3]\n",
    "    epochs = 10\n",
    "    reduced_feature_rbf_count = 3 # liklihood fails for 3,4&5 and gets stuck for 2\n",
    "    frames_for_anomaly = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            with tf.name_scope('Input'):\n",
    "                self.x = tf.placeholder(tf.float32, shape=(None, 158, 238, 3), name='X')\n",
    "                self.x_ = tf.placeholder(tf.float32, shape=(None, 158, 238, 3), name='X_')\n",
    "\n",
    "        self.encoder, self.decoder = self.build_network(self.x)\n",
    "\n",
    "    def build_network(self, x):\n",
    "        def encoder(x):\n",
    "            with self.graph.as_default():\n",
    "                with tf.name_scope('Encoder'):\n",
    "                    x = tf.layers.conv2d(x, filters=32, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 1st Conv', x.get_shape())\n",
    "                    tf.summary.image('encoder_hidden_1', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.max_pooling2d(x, pool_size=(5,5), strides=(1,1), )\n",
    "                    print('After 1st Pooling', x.get_shape())\n",
    "\n",
    "                    x = tf.layers.conv2d(x, filters=16, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 2nd Conv', x.get_shape())\n",
    "                    tf.summary.image('encoder_hidden_2', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.max_pooling2d(x, pool_size=(5,5), strides=(1,1))\n",
    "                    print('After 2nd Pooling', x.get_shape())\n",
    "\n",
    "                    x = tf.layers.conv2d(x, filters=8, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 3rd Conv', x.get_shape())\n",
    "                    tf.summary.image('encoder_hidden_3', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    encoded = tf.layers.max_pooling2d(x, pool_size=(5,5), strides=(1,1))\n",
    "                    print('After 3rd Pooling (Final Encoded)', x.get_shape())\n",
    "                    tf.summary.image('encoder_hidden_final', encoded[:,:,:,0:3], max_outputs=1)\n",
    "                    \n",
    "                    with tf.name_scope('Latent'):\n",
    "                    \n",
    "                        self.latent = tf.layers.dense(tf.contrib.layers.flatten(encoded), #depricated\n",
    "                                                  units=np.prod(Params.latent_feature_count), \n",
    "                                                  activation=tf.nn.relu)\n",
    "\n",
    "                        print('Latent', self.latent.get_shape())\n",
    "                        tf.summary.histogram('Latent', self.latent)\n",
    "\n",
    "                \n",
    "            return encoded\n",
    "\n",
    "        def decoder(encoded):\n",
    "            with self.graph.as_default():\n",
    "                with tf.name_scope('Decoder'):\n",
    "                    #x = tf.reshape(encoded, [-1] + Params.latent_feature_count)\n",
    "                    x = encoded\n",
    "                    x = tf.layers.conv2d_transpose(x, filters=8, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 1st conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_1', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.conv2d_transpose(x, filters=16, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 2nd conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_2', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.conv2d_transpose(x, filters=32, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 3rd conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_3', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.conv2d_transpose(x, filters=32, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 4th conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_4', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    x = tf.layers.conv2d_transpose(x, filters=3, kernel_size=(5,5), strides=(1,1), activation=tf.nn.relu)\n",
    "                    print('After 5th conv transpose', x.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_5', x[:,:,:,0:3],max_outputs=1)\n",
    "                    \n",
    "                    decoded = tf.layers.conv2d_transpose(x, filters=3, kernel_size=(5,5), strides=(1,1), activation=tf.nn.sigmoid)\n",
    "                    print('After 6th conv transpose (final decoded)', decoded.get_shape())\n",
    "                    tf.summary.image('decoder_hidden_decoded', decoded[:,:,:,0:3],max_outputs=1)\n",
    "\n",
    "            return decoded\n",
    "        \n",
    "        return encoder, decoder\n",
    "    \n",
    "    def get_encoded(self):\n",
    "        with self.graph.as_default():\n",
    "            encoded = self.encoder(self.x_)\n",
    "\n",
    "        return encoded\n",
    "    \n",
    "    def get_decoded(self):\n",
    "        encoded = self.get_encoded()\n",
    "        x_hat = self.decoder(encoded)\n",
    "        return x_hat\n",
    "    \n",
    "    def lstm(self, latent):\n",
    "        with self.graph.as_default():\n",
    "\n",
    "            with tf.name_scope('LSTM') as lstm_scope:\n",
    "                #x = tf.layers.dense(latent, units=np.prod(Params.latent_feature_count), activation=tf.nn.relu)\n",
    "\n",
    "                x = latent\n",
    "\n",
    "                lstm = tf.contrib.rnn.BasicLSTMCell(64)\n",
    "\n",
    "                # Grouping 10 images into 1 to form a video clip for which Anomaly detection will be done\n",
    "                x_list = tf.split(x, 10, axis=0) \n",
    "\n",
    "                y_list, self.state = tf.nn.static_rnn(lstm, x_list, dtype = tf.float32)\n",
    "\n",
    "                lstm_out = tf.stack(y_list[-1]) # we only need the last output\n",
    "                lstm_out = tf.layers.dense(lstm_out, Params.reduced_feature_rbf_count)\n",
    "                print('Reduced dimensions for RBF', lstm_out.get_shape())\n",
    "                lstm_out = tf.print(lstm_out, [lstm_out], \"********* Output of LSTM, Input to RBF \", summarize=30)\n",
    "                \n",
    "        return lstm_out\n",
    "\n",
    "    def rbf(self, lstm_output):\n",
    "        with self.graph.as_default():\n",
    "            def get_cost(U, Z, Q): \n",
    "\n",
    "                cost = - (-U - tf.log(Z)) \n",
    "                return tf.reduce_mean(cost)\n",
    "\n",
    "            f = Params.reduced_feature_rbf_count #np.prod(Params.latent_feature_count)\n",
    "\n",
    "\n",
    "            with tf.name_scope('RBF'):\n",
    "                X = lstm_output\n",
    "\n",
    "                mu = tf.Variable(tf.random_uniform([1,f], minval=0.1, dtype=tf.float32))\n",
    "                mu = tf.print(mu, [mu], \"************ mu\")\n",
    "                #Q_ = tf.Variable(tf.truncated_normal([f], mean = 1)) \n",
    "                global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "                sd = tf.Variable(tf.random_uniform([f], minval=0.1, dtype=tf.float32))\n",
    "\n",
    "                sigma = tf.square(sd)\n",
    "                sigma = tf.print(sigma, [sigma], \"************ Sigma (squared) \")\n",
    "                sigma_inverse = tf.reciprocal(sigma)\n",
    "                sigma_inverse = tf.print(sigma_inverse, [sigma_inverse], '************* sigma_inverse')\n",
    "\n",
    "                cov_inverse = tf.diag(sigma_inverse)\n",
    "\n",
    "                det_sigma = tf.reduce_prod(sigma) #tf.pow(sigma, 0.5))\n",
    "                \n",
    "                z = tf.multiply(2*math.pi, det_sigma)\n",
    "                z = tf.print(z, [z], ' ******* z')\n",
    "\n",
    "                with tf.name_scope('Likelihood'):\n",
    "\n",
    "                    M = X - mu\n",
    "                    \n",
    "                    energy = tf.matmul(tf.matmul(M,cov_inverse), tf.transpose(M)) \n",
    "                    #print(\"Energy after matmul\", energy.get_shape())\n",
    "                    #energy = tf.print(energy, [energy], '*********** Energy after matmul')\n",
    "\n",
    "                    energy = tf.reduce_sum(energy, axis = 1, keepdims = True)\n",
    "                    energy = tf.print(energy, [energy], '*********** Energy after summation')\n",
    "                    energy = -1 * tf.multiply(energy, 0.5)\n",
    "                    print('Energy after summation (always negative)', energy.get_shape())\n",
    "\n",
    "                    print('X', X.get_shape())\n",
    "                    print('Covariance', cov_inverse.get_shape())\n",
    "\n",
    "                    expnt = tf.exp(energy)\n",
    "                    print('exponent', expnt.get_shape())\n",
    "                    expnt = tf.print(expnt, [expnt], \"********* Exponent\")\n",
    "\n",
    "                    Y_ = tf.divide(expnt, z)\n",
    "\n",
    "\n",
    "                    #Y_ = tf.layers.dense(Y_, 1)\n",
    "                    rbf_out = Y_ #tf.reduce_mean(Y_) # tf.layers.dense(Y_, 1)\n",
    "                    Y_ = tf.print(Y_, [Y_], 'XXXXXXXXXXXXXXXXXXXX Liklihood XXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "                    print('Y_', Y_.get_shape())\n",
    "\n",
    "                with tf.name_scope('Loss'):\n",
    "                    #cost = -1 * tf.log(Y_ + 0.0001) # Adding a small delta because log is not a continuous function. \n",
    "                    cost = -1 * energy + tf.log(z)\n",
    "                    cost = tf.print(cost,[cost], \"******** Cost(always postive)\")\n",
    "                    loss = tf.reduce_mean(cost) #get_cost(U, Z, Q) # 1- Y_[0]\n",
    "                    loss = tf.print(loss, [loss], \"**************** Loss\")\n",
    "                    tf.summary.scalar('loss', loss)\n",
    "\n",
    "        return mu, sd, rbf_out, loss\n",
    "\n",
    "    def get_spatial_loss(self):\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            \n",
    "            self.x_hat = self.get_decoded()\n",
    "            spatial_loss = tf.losses.mean_squared_error(labels=self.x_, predictions=self.x_hat)\n",
    "                \n",
    "        return spatial_loss\n",
    "    \n",
    "    def get_temporal_loss(self):\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            with tf.name_scope('Temporal_Autoencoder'):\n",
    "                \n",
    "                lstm_out = self.lstm(self.latent)\n",
    "                print(\"LSTM: Images will be grouped (e.g. 10 images to 1 clip) into video clips when fed to LSTM\",\n",
    "                      lstm_out.get_shape())\n",
    "                tf.summary.histogram(\"LSTM\", lstm_out)\n",
    "\n",
    "                self.mean, self.sigma, self.likelihood, likelihood_loss = self.rbf(lstm_out)\n",
    "                print(\"Likelihood: \", self.likelihood.get_shape())\n",
    "                tf.summary.scalar(\"Temporal_Loss\", likelihood_loss)\n",
    "                \n",
    "        return likelihood_loss\n",
    "    \n",
    "    \n",
    "    def get_optimizer_loss(self):\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            self.x_hat = self.get_decoded()\n",
    "\n",
    "            with tf.name_scope('Optimization'):\n",
    "                \n",
    "                spatial_loss = self.get_spatial_loss()\n",
    "                temporal_loss = self.get_temporal_loss()\n",
    "                \n",
    "                loss = spatial_loss + temporal_loss\n",
    "                tf.summary.scalar(\"loss\",loss)\n",
    "                \n",
    "                starter_learning_rate = 0.001\n",
    "                global_step = tf.Variable(0, trainable=False)\n",
    "                #global_step = tf.print(global_step, [global_step], \"########## Global Step Completed #############\")\n",
    "                learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                                   int(Params.epochs / 3), 0.5, staircase=True)\n",
    "                train = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "                tf.summary.scalar(\"learning_rate\",learning_rate)\n",
    "\n",
    "            merged = tf.summary.merge_all()\n",
    "        return train, merged, loss, self.likelihood, self.mean, self.sigma\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1st Conv (?, 154, 234, 32)\n",
      "After 1st Pooling (?, 150, 230, 32)\n",
      "After 2nd Conv (?, 146, 226, 16)\n",
      "After 2nd Pooling (?, 142, 222, 16)\n",
      "After 3rd Conv (?, 138, 218, 8)\n",
      "After 3rd Pooling (Final Encoded) (?, 138, 218, 8)\n",
      "Latent (?, 300)\n",
      "After 1st conv transpose (?, 138, 218, 8)\n",
      "After 2nd conv transpose (?, 142, 222, 16)\n",
      "After 3rd conv transpose (?, 146, 226, 32)\n",
      "After 4th conv transpose (?, 150, 230, 32)\n",
      "After 5th conv transpose (?, 154, 234, 3)\n",
      "After 6th conv transpose (final decoded) (?, 158, 238, 3)\n",
      "After 1st Conv (?, 154, 234, 32)\n",
      "After 1st Pooling (?, 150, 230, 32)\n",
      "After 2nd Conv (?, 146, 226, 16)\n",
      "After 2nd Pooling (?, 142, 222, 16)\n",
      "After 3rd Conv (?, 138, 218, 8)\n",
      "After 3rd Pooling (Final Encoded) (?, 138, 218, 8)\n",
      "Latent (?, 300)\n",
      "After 1st conv transpose (?, 138, 218, 8)\n",
      "After 2nd conv transpose (?, 142, 222, 16)\n",
      "After 3rd conv transpose (?, 146, 226, 32)\n",
      "After 4th conv transpose (?, 150, 230, 32)\n",
      "After 5th conv transpose (?, 154, 234, 3)\n",
      "After 6th conv transpose (final decoded) (?, 158, 238, 3)\n",
      "Reduced dimensions for RBF (?, 3)\n",
      "LSTM: Images will be grouped (e.g. 10 images to 1 clip) into video clips when fed to LSTM (?, 3)\n",
      "Energy after summation (always negative) (?, 1)\n",
      "X (?, 3)\n",
      "Covariance (3, 3)\n",
      "exponent (?, 1)\n",
      "Y_ (?, 1)\n",
      "Likelihood:  (?, 1)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [229408,300] and type float\n\t [[Node: dense_1/kernel/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [229408,300] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'dense_1/kernel/Adam/Initializer/zeros', defined at:\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-c3a1a42d6e6f>\", line 9, in <module>\n    optim_loss = network.get_optimizer_loss()\n  File \"<ipython-input-6-1e690e200a12>\", line 230, in get_optimizer_loss\n    train = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 409, in minimize\n    name=name)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 585, in apply_gradients\n    self._create_slots(var_list)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 127, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 1130, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 181, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 155, in create_slot_with_initializer\n    dtype)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1328, in get_variable\n    constraint=constraint)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1090, in get_variable\n    constraint=constraint)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 435, in get_variable\n    constraint=constraint)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 404, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 796, in _get_single_variable\n    use_resource=use_resource)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2234, in variable\n    use_resource=use_resource)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2224, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2207, in default_variable_creator\n    constraint=constraint)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 259, in __init__\n    constraint=constraint)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 368, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 780, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 99, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1550, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2793, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [229408,300] and type float\n\t [[Node: dense_1/kernel/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [229408,300] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [229408,300] and type float\n\t [[Node: dense_1/kernel/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [229408,300] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c3a1a42d6e6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logdir/cae_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [229408,300] and type float\n\t [[Node: dense_1/kernel/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [229408,300] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'dense_1/kernel/Adam/Initializer/zeros', defined at:\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/kvpcloud/.conda/envs/p3_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-c3a1a42d6e6f>\", line 9, in <module>\n    optim_loss = network.get_optimizer_loss()\n  File \"<ipython-input-6-1e690e200a12>\", line 230, in get_optimizer_loss\n    train = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 409, in minimize\n    name=name)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 585, in apply_gradients\n    self._create_slots(var_list)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 127, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 1130, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 181, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 155, in create_slot_with_initializer\n    dtype)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1328, in get_variable\n    constraint=constraint)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1090, in get_variable\n    constraint=constraint)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 435, in get_variable\n    constraint=constraint)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 404, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 796, in _get_single_variable\n    use_resource=use_resource)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2234, in variable\n    use_resource=use_resource)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2224, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2207, in default_variable_creator\n    constraint=constraint)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 259, in __init__\n    constraint=constraint)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 368, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 780, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 99, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1550, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2793, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/home/kvpcloud/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [229408,300] and type float\n\t [[Node: dense_1/kernel/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [229408,300] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "loss_arr=[]\n",
    "likelihood_arr=[]\n",
    "network = Network()\n",
    "\n",
    "m_b_s = 3*Params.frames_for_anomaly\n",
    "with tf.Session(graph=network.graph) as sess:\n",
    "\n",
    "    \n",
    "    optim_loss = network.get_optimizer_loss()\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter('logdir/cae_train', sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(Params.epochs):\n",
    "        m_b_s_old = 0\n",
    "        for m_b_s_new in range(m_b_s, Dataset.train_images_.shape[0], m_b_s  ):\n",
    "            _, merged, loss, likelihood, mean, sigma = sess.run(optim_loss, \n",
    "                                                   feed_dict={network.x:Dataset.train_images_[m_b_s_old:m_b_s_new,...],\n",
    "                                                            network.x_: Dataset.train_images[m_b_s_old:m_b_s_new,...]})\n",
    "\n",
    "            m_b_s_old = m_b_s_new\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            print('epoch:', epoch, 'loss:', loss, 'Likelihood:', np.asarray(likelihood).flatten(), 'Mean:', np.asarray(mean).flatten())\n",
    "            train_writer.add_summary(merged, epoch)\n",
    "            loss_arr.append(loss)\n",
    "            likelihood_arr.append(np.mean(likelihood))\n",
    "        \n",
    "    \n",
    "    #Dataset.latent = sess.run(network.latent,feed_dict={network.x:Dataset.train_images_,\n",
    "    #                                        network.x_: Dataset.train_images})\n",
    "    \n",
    "    \n",
    "    #print('Getting predictions for Training Data')\n",
    "    #Dataset.reproduced_images_training = sess.run(network.x_hat,feed_dict={network.x:Dataset.train_images_[:30,... ],\n",
    "    #                                        network.x_: Dataset.train_images[:30,... ]})\n",
    "    #Dataset.likelihood_training, Dataset.mean_training, Dataset.sigma_training = sess.run([network.likelihood, network.mean, network.sigma],\n",
    "    #                                                                                      feed_dict={network.x:Dataset.train_images_[:30,... ],\n",
    "    #                                                                                    network.x_: Dataset.train_images[:30,... ]})\n",
    "    \n",
    "    #print('Getting predictions for Testing Data')\n",
    "    #Dataset.reproduced_images = sess.run(network.x_hat,feed_dict={network.x:Dataset.test_images_[:30,... ],\n",
    "    #                                        network.x_: Dataset.test_images[:30,... ]})\n",
    "    #Dataset.likelihood, Dataset.mean, Dataset.sigma = sess.run([network.likelihood, network.mean, network.sigma],\n",
    "    #                                                           feed_dict={network.x:Dataset.test_images_[:30,... ],\n",
    "    #                                                            network.x_: Dataset.test_images[:30,... ]})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_arr, label='Loss')\n",
    "plt.plot(likelihood_arr, label='Likelihood')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('{}/latent_train'.format(Dataset.main),Dataset.latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6,5, figsize=(25,8))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, imgs in enumerate(Dataset.test_images_[:30]):\n",
    "    axs[i].imshow(imgs[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6,5, figsize=(25,8))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, imgs in enumerate(Dataset.reproduced_images[:30]):\n",
    "    axs[i].imshow(imgs[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.likelihood, Dataset.mean, Dataset.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6,5, figsize=(25,8))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, imgs in enumerate(Dataset.train_images_[:30]):\n",
    "    axs[i].imshow(imgs[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6,5, figsize=(25,8))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, imgs in enumerate(Dataset.reproduced_images_training[:30]):\n",
    "    axs[i].imshow(imgs[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.likelihood_training, Dataset.mean_training, Dataset.sigma_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
